{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pysam\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyfaidx import Fasta\n",
    "from collections import *\n",
    "from tools.intervals import *\n",
    "from tools.misc import *\n",
    "from tools.procOps import *\n",
    "from tools.fileOps import *\n",
    "from tools.bio import *\n",
    "from tools.psl import *\n",
    "from itertools import *\n",
    "import bisect\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MsaRecord(object):\n",
    "    \"\"\"Convenience holder for alignment information\"\"\"\n",
    "    def __init__(self, msa_start, msa_stop, qname, seq):\n",
    "        self.msa_start = msa_start\n",
    "        self.msa_stop = msa_stop\n",
    "        self.qname = qname\n",
    "        self.seq = seq\n",
    "\n",
    "\n",
    "def find_closest(numeric_list, query_number):\n",
    "    \"\"\"\n",
    "    Given a list of numbers, and a single query number, find the number in the sorted list that is numerically\n",
    "    closest to the query number. Uses list bisection to do so, and so should be O(log n)\n",
    "    \"\"\"\n",
    "    sorted_numeric_list = sorted(numeric_list)\n",
    "    pos = bisect.bisect_left(sorted_numeric_list, query_number)\n",
    "    if pos == 0:\n",
    "        return sorted_numeric_list[0]\n",
    "    if pos == len(sorted_numeric_list):\n",
    "        return sorted_numeric_list[-1]\n",
    "    before = sorted_numeric_list[pos - 1]\n",
    "    after = sorted_numeric_list[pos]\n",
    "    if after - query_number < query_number - before:\n",
    "        return after\n",
    "    else:\n",
    "        return before\n",
    "\n",
    "\n",
    "def find_overlap(b1, b2, spacer=50):\n",
    "    delta = b1.msa_stop - b2.msa_start\n",
    "    b1_seq = b1.seq[-(delta + spacer):]\n",
    "    b2_seq = b2.seq[:delta + spacer]\n",
    "    aln = perform_aln(b1_seq, b2_seq)\n",
    "    if len(aln) == 0:\n",
    "        s = b1.seq[:-delta]\n",
    "        assert len(s) > 0\n",
    "        return s\n",
    "    else:\n",
    "        psl = sorted([PslRow(x.split('\\t')) for x in aln], key=lambda x: x.coverage)[-1]\n",
    "        cutoff = psl.query_coordinate_to_target(psl.q_end - 1) + 1\n",
    "        return b1.seq[:-(cutoff - spacer)]\n",
    "\n",
    "\n",
    "def merge_same(b1, b2):\n",
    "    with TemporaryFilePath() as f, TemporaryFilePath() as f2:\n",
    "        with open(f, 'w') as outf:\n",
    "            write_fasta(outf, 'b1', b1.seq)\n",
    "            write_fasta(outf, 'b2', b2.seq)\n",
    "        cmd = ['muscle', '-in', f, '-out', f2]\n",
    "        run_proc(cmd)\n",
    "        fa = Fasta(f2)\n",
    "        seq = []\n",
    "        for x, y in zip(*[fa['b1'], fa['b2']]):\n",
    "            if x == '-':\n",
    "                seq.append(y)\n",
    "            else:\n",
    "                seq.append(x)\n",
    "        return ''.join(seq)\n",
    "\n",
    "\n",
    "def perform_aln(b1_seq, b2_seq):\n",
    "    with TemporaryFilePath() as b1_f, TemporaryFilePath() as b2_f:\n",
    "        with open(b1_f, 'w') as b1_f_h:\n",
    "            write_fasta(b1_f_h, 'b1', b1_seq)\n",
    "        with open(b2_f, 'w') as b2_f_h:\n",
    "            write_fasta(b2_f_h, 'b2', b2_seq)\n",
    "        cmd = ['blat', b1_f, b2_f, '-noHead', '/dev/stdout']\n",
    "        return call_proc_lines(cmd)[:-2]\n",
    "\n",
    "\n",
    "def construct_hg38_map(n2nl_aln, hg38_bam):\n",
    "    \"\"\"Constructs a map of hg38 position -> sequence alignment position -> MSA position\"\"\"\n",
    "    # construct sequence alignment position -> MSA position map using the MSA\n",
    "    aln_f = Fasta(n2nl_aln)\n",
    "    seq_aln_map = defaultdict(dict)\n",
    "    for name, seq in aln_f.iteritems():\n",
    "        seq_pos = 0\n",
    "        for aln_pos, x in enumerate(str(seq)):\n",
    "            seq_aln_map[name][seq_pos] = aln_pos\n",
    "            if x != '-':\n",
    "                seq_pos += 1\n",
    "\n",
    "    # find maximum position for reversing negative strand\n",
    "    max_pos = {x: max(y.keys()) for x, y in seq_aln_map.iteritems()}\n",
    "\n",
    "    # construct a hg38 -> sequence positions using the sequences trivially mapped back to hg38\n",
    "    hg38_map = {}\n",
    "    for rec in pysam.Samfile(hg38_bam):\n",
    "        m = {y: x for x, y in rec.aligned_pairs}\n",
    "        # invert positions for negative strand genes\n",
    "        if rec.qname in ['NOTCH2', 'NOTCH2NL-A', 'NOTCH2NL-B']:\n",
    "            m = {x: max_pos[rec.qname] - y for x, y in m.iteritems()}\n",
    "        hg38_map[rec.qname] = m\n",
    "\n",
    "    # construct a table mapping each alignment position to all hg38 positions\n",
    "    r = defaultdict(dict)\n",
    "    for name, pos_map in hg38_map.iteritems():\n",
    "        for hg38_pos, seq_pos in pos_map.iteritems():\n",
    "            aln_pos = seq_aln_map[name][seq_pos]\n",
    "            r[name][aln_pos] = hg38_pos\n",
    "\n",
    "    # now invert this map, so that we have our hg38 -> aln map\n",
    "    final_map = {}\n",
    "    for name in r:\n",
    "        for aln_pos in r[name]:\n",
    "            hg38_pos = r[name][aln_pos]\n",
    "            assert hg38_pos not in final_map\n",
    "            final_map[hg38_pos] = aln_pos\n",
    "\n",
    "    return final_map\n",
    "\n",
    "\n",
    "def load_alignments(bam, name, regions_of_interest, position_map, sorted_positions):\n",
    "    \"\"\"\n",
    "    1) Load all alignments of contigs to hg38\n",
    "    2) filter for those that overlap the MSA\n",
    "    3) sort them by MSA positions based on the position map\n",
    "    4) Filter for entirely overlapping\n",
    "    5) return sorted lists of MsaRecords\n",
    "    \"\"\"\n",
    "    msa_blocks = []\n",
    "    for aln in pysam.Samfile(bam):\n",
    "        if aln.is_unmapped:\n",
    "            continue\n",
    "        # make sure this alignment overlaps notch\n",
    "        start = aln.reference_start\n",
    "        end = aln.reference_end\n",
    "        c = ChromosomeInterval('chr1', start, end, '.')\n",
    "        # filter for overlapping our regions and not being too short\n",
    "        if not interval_not_intersect_intervals(regions_of_interest, c) and len(c) > 100:\n",
    "            # find the closest positions in hg38 that are present in our MSA\n",
    "            closest_start = find_closest(sorted_positions, start)\n",
    "            closest_stop = find_closest(sorted_positions, end)\n",
    "            msa_start = position_map[closest_start]\n",
    "            msa_stop = position_map[closest_stop]\n",
    "            if msa_start > msa_stop:  # handle negative strand\n",
    "                msa_start, msa_stop = msa_stop, msa_start\n",
    "                seq = reverse_complement(aln.seq)\n",
    "            else:\n",
    "                seq = aln.seq\n",
    "            b = MsaRecord(msa_start, msa_stop, aln.qname, seq)\n",
    "            msa_blocks.append(b)\n",
    "\n",
    "    # sort by MSA position\n",
    "    sorted_msa_blocks = sorted(msa_blocks, key=lambda x: x.msa_start)\n",
    "\n",
    "    # filter blocks for those that are entirely a subset of another\n",
    "    # this removes misassemblies\n",
    "    intervals = [ChromosomeInterval('', x.msa_start, x.msa_stop, '.', x) for x in sorted_msa_blocks]\n",
    "    bad_intervals = set()\n",
    "    for i1, i2 in combinations(intervals, 2):\n",
    "        if i1.proper_subset(i2):\n",
    "            bad_intervals.add(i1)\n",
    "        elif i2.proper_subset(i1):\n",
    "            bad_intervals.add(i2)\n",
    "    filtered_msa_blocks = [x.data for x in intervals if x not in bad_intervals]\n",
    "\n",
    "    return filtered_msa_blocks\n",
    "\n",
    "\n",
    "def scaffold_alignments(filtered_msa_blocks):\n",
    "    \"\"\"\n",
    "    Takes a sorted list of MsaRecord objects and scaffolds them\n",
    "    \"\"\"\n",
    "    seq = []\n",
    "    # construct a pairwise iterator over the filtered_msa_blocks\n",
    "    a, b = tee(filtered_msa_blocks)\n",
    "    _ = next(b, None)\n",
    "    # keep track of sequences that got merged, so we don't merge them again\n",
    "    merged = set()\n",
    "    for i, (b1, b2) in enumerate(izip(a, b)):\n",
    "        if b1.qname in merged:\n",
    "                continue\n",
    "        elif b1.qname == b2.qname:\n",
    "            seq.append(merge_same(b1, b2))\n",
    "            merged.add(b1.qname)\n",
    "        elif b2.msa_start < b1.msa_stop:  # we have an overlap, resolve via pairwise alignment\n",
    "            seq.append(find_overlap(b1, b2))\n",
    "        elif b1.msa_stop == b2.msa_start:  # exactly contiguous, just add b1 and continue\n",
    "            seq.append(b1.seq)\n",
    "        else:  # we have a unknown gap, so add b1 then a gap\n",
    "            seq.append(b1.seq)\n",
    "            seq.append(''.join(['N'] * 100))\n",
    "        # add the final b2 sequence\n",
    "    seq.append(b2.seq)\n",
    "    return ''.join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n2nl_aln = '/hive/users/ifiddes/notch_brian_viz/try_bwa/notch2nl_alignment.fa'\n",
    "hg38_bam = '/hive/users/ifiddes/notch_brian_viz/try_bwa/hg38_mapped.bam'\n",
    "n2_regions = '/hive/users/ifiddes/notch_brian_viz/try_bwa/n2_regions.bed'\n",
    "bam = 'hg38_mapped_contigs/C1.hg38.bam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the intervals we are interested in\n",
    "start_stop_positions = {x.split()[3]: (x.split()[1], x.split()[2]) for x in open(n2_regions)}\n",
    "start_stop_positions = {x: map(int, y) for x, y in start_stop_positions.iteritems()}\n",
    "\n",
    "# load the map of hg38 positions to alignment positions\n",
    "position_map = construct_hg38_map(n2nl_aln, hg38_bam)\n",
    "# construct a sorted list of hg38 positions\n",
    "sorted_positions = sorted(position_map.keys())\n",
    "\n",
    "# construct our regions of interest\n",
    "regions_of_interest = []\n",
    "for start, stop in start_stop_positions.itervalues():\n",
    "    regions_of_interest.append(ChromosomeInterval('chr1', start, stop, '.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_msa_blocks = load_alignments(bam, name, regions_of_interest, position_map, sorted_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26145 119800 contig-100_0\n",
      "119902 120700 contig-100_71\n",
      "120676 121608 contig-100_61\n",
      "121509 129212 contig-100_5\n",
      "129269 153395 contig-100_2\n",
      "153399 156152 contig-100_20\n",
      "156179 157814 contig-100_29\n",
      "157792 162896 contig-100_8\n",
      "162873 163827 contig-100_52\n",
      "163795 166955 contig-100_15\n",
      "166856 168246 contig-100_44\n",
      "168146 196751 contig-100_1\n",
      "196727 205462 contig-100_4\n",
      "205438 208034 contig-100_14\n"
     ]
    }
   ],
   "source": [
    "for x in filtered_msa_blocks:\n",
    "    print x.msa_start, x.msa_stop, x.qname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gap contig-100_0 contig-100_71\n",
      "overlap contig-100_71 contig-100_61\n",
      "overlap contig-100_61 contig-100_5\n",
      "gap contig-100_5 contig-100_2\n",
      "gap contig-100_2 contig-100_20\n",
      "gap contig-100_20 contig-100_29\n",
      "overlap contig-100_29 contig-100_8\n",
      "overlap contig-100_8 contig-100_52\n",
      "overlap contig-100_52 contig-100_15\n",
      "overlap contig-100_15 contig-100_44\n",
      "overlap contig-100_44 contig-100_1\n",
      "overlap contig-100_1 contig-100_4\n",
      "overlap contig-100_4 contig-100_14\n"
     ]
    }
   ],
   "source": [
    "seq = []\n",
    "# construct a pairwise iterator over the filtered_msa_blocks\n",
    "a, b = tee(filtered_msa_blocks)\n",
    "_ = next(b, None)\n",
    "# keep track of sequences that got merged, so we don't merge them again\n",
    "merged = set()\n",
    "with open('test.fa', 'w') as outf:\n",
    "    for i, (b1, b2) in enumerate(izip(a, b)):\n",
    "        if b1.qname in merged:\n",
    "                continue\n",
    "        elif b1.qname == b2.qname:\n",
    "            seq.append(merge_same(b1, b2))\n",
    "            merged.add(b1.qname)\n",
    "            print 'merged', b1.qname, b2.qname\n",
    "        elif b2.msa_start < b1.msa_stop:  # we have an overlap, resolve via pairwise alignment\n",
    "            s = find_overlap(b1, b2)\n",
    "            seq.append(s)\n",
    "            print 'overlap', b1.qname, b2.qname\n",
    "            write_fasta(outf, b1.qname + b2.qname, ''.join([s[-200:], b2.seq[:200]]))\n",
    "        elif b1.msa_stop == b2.msa_start:  # exactly contiguous, just add b1 and continue\n",
    "            seq.append(b1.seq)\n",
    "            print 'contiguous', b1.qname, b2.qname\n",
    "        else:  # we have a unknown gap, so add b1 then a gap\n",
    "            seq.append(b1.seq)\n",
    "            seq.append(''.join(['N'] * 100))\n",
    "            print 'gap', b1.qname, b2.qname\n",
    "            write_fasta(outf, b1.qname + b2.qname, ''.join([b1.seq[-200:], b2.seq[:200]]))\n",
    "        # add the final b2 sequence\n",
    "    seq.append(b2.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first, construct a map of sequence positions to alignment positions\n",
    "aln_f = Fasta('notch2nl_alignment.fa')\n",
    "seq_aln_map = defaultdict(dict)\n",
    "for name, seq in aln_f.iteritems():\n",
    "    seq_pos = 0\n",
    "    for aln_pos, x in enumerate(str(seq)):\n",
    "        seq_aln_map[name][seq_pos] = aln_pos\n",
    "        if x != '-':\n",
    "            seq_pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find maximum position for reversing negative strand\n",
    "max_pos = {x: max(y.keys()) for x, y in seq_aln_map.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# next, construct a map of hg38 positions to sequence positions using the alignment\n",
    "hg38_map = {}\n",
    "for rec in pysam.Samfile('hg38_mapped.bam'):\n",
    "    m = {y: x for x, y in rec.aligned_pairs}\n",
    "    if rec.qname in ['NOTCH2', 'NOTCH2NL-A', 'NOTCH2NL-B']:\n",
    "        m = {x: max_pos[rec.qname] - y for x, y in m.iteritems()}\n",
    "    hg38_map[rec.qname] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOTCH2</th>\n",
       "      <th>NOTCH2NL-A</th>\n",
       "      <th>NOTCH2NL-B</th>\n",
       "      <th>NOTCH2NL-C</th>\n",
       "      <th>NOTCH2NL-D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120189999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149328817.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120189998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148801426.0</td>\n",
       "      <td>149328818.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120189997.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148801425.0</td>\n",
       "      <td>149328819.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120189996.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148801424.0</td>\n",
       "      <td>149328820.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120189995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148801423.0</td>\n",
       "      <td>149328821.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NOTCH2  NOTCH2NL-A   NOTCH2NL-B   NOTCH2NL-C  NOTCH2NL-D\n",
       "0  120189999.0         NaN          NaN  149328817.0         NaN\n",
       "1  120189998.0         NaN  148801426.0  149328818.0         NaN\n",
       "2  120189997.0         NaN  148801425.0  149328819.0         NaN\n",
       "3  120189996.0         NaN  148801424.0  149328820.0         NaN\n",
       "4  120189995.0         NaN  148801423.0  149328821.0         NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a table mapping each alignment position to all hg38 positions\n",
    "r = defaultdict(dict)\n",
    "for name, pos_map in hg38_map.iteritems():\n",
    "    for hg38_pos, seq_pos in pos_map.iteritems():\n",
    "        aln_pos = seq_aln_map[name][seq_pos]\n",
    "        r[name][aln_pos] = hg38_pos\n",
    "\n",
    "df = pd.DataFrame.from_dict(r)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now invert this map, so that we have our hg38 -> aln map\n",
    "final_map = {}\n",
    "for name in r:\n",
    "    for aln_pos in r[name]:\n",
    "        hg38_pos = r[name][aln_pos]\n",
    "        assert hg38_pos not in final_map\n",
    "        final_map[hg38_pos] = aln_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the intervals we are interested in\n",
    "start_stop_positions = {x.split()[3]: (x.split()[1], x.split()[2]) for x in open('n2_regions.bed')}\n",
    "start_stop_positions = {x: map(int, y) for x, y in start_stop_positions.iteritems()}\n",
    "\n",
    "# construct our regions of interest\n",
    "regions_of_interest = []\n",
    "for start, stop in start_stop_positions.itervalues():\n",
    "    regions_of_interest.append(ChromosomeInterval('chr1', start, stop, '.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load all the alignments, by qname\n",
    "aln_map = {}\n",
    "base_dir = '/hive/users/ifiddes/notch2nl_berkeley_data/E2del19N_E2del68_combined_longranger/E2del68_E2del19N_combined/new-assembly/hg38_mapped_contigs'\n",
    "for name in ['A1', 'A2', 'B1', 'B2', 'C1', 'C2', 'D1', 'D2', 'N1', 'N2']:\n",
    "    s = os.path.join(base_dir, '{}.hg38.bam'.format(name))\n",
    "    aln_map[name] = list(pysam.Samfile(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract all alignments, discarding those not in our ROIs\n",
    "blocks = {}\n",
    "for name in aln_map:\n",
    "    b = []\n",
    "    for aln in aln_map[name]:\n",
    "        if aln.is_unmapped:\n",
    "            continue\n",
    "        start = aln.reference_start\n",
    "        end = aln.reference_end\n",
    "        c = ChromosomeInterval('chr1', start, end, '.')\n",
    "        if not interval_not_intersect_intervals(regions_of_interest, c) and len(c) > 100:\n",
    "            b.append([start, end, aln.qname, aln.seq, aln.qstart, aln.qstart + aln.alen])\n",
    "    blocks[name] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120126469 120136856 contig-100_4 7 10394\n",
      "146148508 146159995 contig-100_7 3 11490\n",
      "146159966 146192832 contig-100_1 54 32920\n",
      "146207843 146252183 contig-100_0 0 44340\n",
      "146252085 146257333 contig-100_11 0 5248\n",
      "146286025 146288109 contig-100_20 0 2084\n",
      "148643514 148658579 contig-100_6 48 15113\n",
      "148708073 148736282 contig-100_2 0 28209\n",
      "148745798 148755309 contig-100_4 0 9511\n",
      "148755275 148779513 contig-100_3 32 24270\n",
      "148769779 148769881 contig-100_160 257 359\n",
      "149332986 149335419 contig-100_16 0 2433\n",
      "149335395 149350493 contig-100_5 56 15154\n"
     ]
    }
   ],
   "source": [
    "for b in blocks['A2']:\n",
    "    print b[0], b[1], b[2], b[4], b[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each alignment, determine the interval in the MSA\n",
    "# use a closest finding algorithm to deal with unaligned regions\n",
    "\n",
    "class Record(object):\n",
    "    def __init__(self, msa_start, msa_stop, qname, seq, seq_start, seq_end):\n",
    "        self.msa_start = msa_start\n",
    "        self.msa_stop = msa_stop\n",
    "        self.qname = qname\n",
    "        self.seq = seq\n",
    "        self.seq_start = seq_start\n",
    "        self.seq_end = seq_end\n",
    "\n",
    "def find_closest(numeric_list, query_number):\n",
    "    \"\"\"\n",
    "    Given a list of numbers, and a single query number, find the number in the sorted list that is numerically\n",
    "    closest to the query number. Uses list bisection to do so, and so should be O(log n)\n",
    "    \"\"\"\n",
    "    sorted_numeric_list = sorted(numeric_list)\n",
    "    pos = bisect.bisect_left(sorted_numeric_list, query_number)\n",
    "    if pos == 0:\n",
    "        return sorted_numeric_list[0]\n",
    "    if pos == len(sorted_numeric_list):\n",
    "        return sorted_numeric_list[-1]\n",
    "    before = sorted_numeric_list[pos - 1]\n",
    "    after = sorted_numeric_list[pos]\n",
    "    if after - query_number < query_number - before:\n",
    "        return after\n",
    "    else:\n",
    "        return before\n",
    "\n",
    "sorted_positions = sorted(final_map.keys())\n",
    "\n",
    "msa_blocks = {}\n",
    "for name, b in blocks.iteritems():\n",
    "    mb = []\n",
    "    for start, end, qname, seq, seq_start, seq_end in b:\n",
    "        closest_start = find_closest(sorted_positions, start)\n",
    "        closest_stop = find_closest(sorted_positions, end)\n",
    "        msa_start = final_map[closest_start]\n",
    "        msa_stop = final_map[closest_stop]\n",
    "        if msa_start > msa_stop:  # handle negative strand\n",
    "            msa_start, msa_stop = msa_stop, msa_start\n",
    "            seq = reverse_complement(seq)\n",
    "        # TODO: Record doesn't need seq_start or seq_end\n",
    "        with TemporaryFilePath() as tmp_f:\n",
    "            write_fasta(tmp_f, qname, seq)\n",
    "            cmd = ['faPolyASizes', tmp_f, '/dev/stdout']\n",
    "            r = call_proc_lines(cmd)\n",
    "        r = r[0].split()\n",
    "        start = int(r[-2])\n",
    "        stop = int(r[-1])\n",
    "        seq = seq[start:len(seq) - stop]\n",
    "        assert len(seq) > 0\n",
    "        mb.append(Record(msa_start, msa_stop, qname, seq, seq_start, seq_end))\n",
    "    # sort these to be in notch2nl order\n",
    "    mb = sorted(mb, key=lambda x: x.msa_start)\n",
    "    msa_blocks[name] = mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4172 6605 contig-100_16 0 2433 2411\n",
      "6581 25896 contig-100_5 56 15154 15207\n",
      "26147 50433 contig-100_3 32 24270 24230\n",
      "35809 35911 contig-100_160 257 359 359\n",
      "50399 60617 contig-100_4 0 9511 9497\n",
      "53285 67570 contig-100_4 7 10394 17154\n",
      "67552 69636 contig-100_20 0 2084 2067\n",
      "70162 98420 contig-100_2 0 28209 28206\n",
      "98405 103668 contig-100_11 0 5248 5248\n",
      "103570 148362 contig-100_0 0 44340 44344\n",
      "148367 163827 contig-100_6 48 15113 15162\n",
      "163793 196751 contig-100_1 54 32920 32883\n",
      "196722 208040 contig-100_7 3 11490 11428\n"
     ]
    }
   ],
   "source": [
    "for x in msa_blocks['A2']:\n",
    "    print x.msa_start, x.msa_stop, x.qname, x.seq_start, x.seq_end, len(x.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter blocks for those that are entirely a subset of another\n",
    "# this removes misassemblies\n",
    "filtered_blocks = {}\n",
    "for name, mb in msa_blocks.iteritems():\n",
    "    intervals = [ChromosomeInterval('', x.msa_start, x.msa_stop, '.', x) for x in mb]\n",
    "    bad_intervals = set()\n",
    "    for i1, i2 in combinations(intervals, 2):\n",
    "        if i1.proper_subset(i2):\n",
    "            bad_intervals.add(i1)\n",
    "        elif i2.proper_subset(i1):\n",
    "            bad_intervals.add(i2)\n",
    "    filtered_blocks[name] = [x.data for x in intervals if x not in bad_intervals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4172 6605 contig-100_16 0 2433 2411\n",
      "6581 25896 contig-100_5 56 15154 15207\n",
      "26147 50433 contig-100_3 32 24270 24230\n",
      "50399 60617 contig-100_4 0 9511 9497\n",
      "53285 67570 contig-100_4 7 10394 17154\n",
      "67552 69636 contig-100_20 0 2084 2067\n",
      "70162 98420 contig-100_2 0 28209 28206\n",
      "98405 103668 contig-100_11 0 5248 5248\n",
      "103570 148362 contig-100_0 0 44340 44344\n",
      "148367 163827 contig-100_6 48 15113 15162\n",
      "163793 196751 contig-100_1 54 32920 32883\n",
      "196722 208040 contig-100_7 3 11490 11428\n"
     ]
    }
   ],
   "source": [
    "for x in filtered_blocks['A2']:\n",
    "    print x.msa_start, x.msa_stop, x.qname, x.seq_start, x.seq_end, len(x.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_overlap(b1, b2, spacer=50):\n",
    "    delta = b1.msa_stop - b2.msa_start \n",
    "    b1_seq = b1.seq[-(delta + spacer):]\n",
    "    b2_seq = b2.seq[:delta + spacer]\n",
    "    aln = perform_aln(b1_seq, b2_seq)\n",
    "    if len(aln) == 0:\n",
    "        s = b1.seq[:-delta]\n",
    "        assert len(s) > 0\n",
    "        return s\n",
    "    else:\n",
    "        psl = sorted([PslRow(x.split('\\t')) for x in aln], key=lambda x: x.coverage)[-1]\n",
    "        cutoff = psl.query_coordinate_to_target(psl.q_end - 1) + 1\n",
    "        return b1.seq[:-cutoff]\n",
    "\n",
    "def merge_same(b1, b2):\n",
    "    with TemporaryFilePath() as f, TemporaryFilePath() as f2:\n",
    "        with open(f, 'w') as outf:\n",
    "            write_fasta(outf, 'b1', b1.seq)\n",
    "            write_fasta(outf, 'b2', b2.seq)\n",
    "        cmd = ['muscle', '-in', f, '-out', f2]\n",
    "        run_proc(cmd)\n",
    "        fa = Fasta(f2)\n",
    "        seq = []\n",
    "        for x, y in zip(*[fa['b1'], fa['b2']]):\n",
    "            if x == '-':\n",
    "                seq.append(y)\n",
    "            else:\n",
    "                seq.append(x)\n",
    "        return ''.join(seq)\n",
    "    \n",
    "def perform_aln(b1_seq, b2_seq):\n",
    "    with TemporaryFilePath() as b1_f, TemporaryFilePath() as b2_f:\n",
    "        with open(b1_f, 'w') as b1_f_h:\n",
    "            write_fasta(b1_f_h, 'b1', b1_seq)\n",
    "        with open(b2_f, 'w') as b2_f_h:\n",
    "            write_fasta(b2_f_h, 'b1', b2_seq)\n",
    "        cmd = ['blat', b1_f, b2_f, '-noHead', '/dev/stdout']\n",
    "        return call_proc_lines(cmd)[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seqs = {}\n",
    "for name, mb in filtered_blocks.iteritems():\n",
    "    seq = []\n",
    "    a, b = tee(mb)\n",
    "    _ = next(b, None)\n",
    "    merged = set()\n",
    "    for i, (b1, b2) in enumerate(izip(a, b)):\n",
    "        if b1.qname in merged:\n",
    "                continue\n",
    "        elif b1.qname == b2.qname:\n",
    "            seq.append(merge_same(b1, b2))\n",
    "            merged.add(b1.qname)\n",
    "        elif b2.msa_start < b1.msa_stop:  # we have an overlap, resolve via pairwise alignment\n",
    "            seq.append(find_overlap(b1, b2))\n",
    "        elif b1.msa_stop == b2.msa_start:  # exactly contiguous, just add b1 and continue\n",
    "            seq.append(b1.seq)\n",
    "        else:  # we have a unknown gap, so add b1 then a gap\n",
    "            seq.append(b1.seq)\n",
    "            seq.append(''.join(['N'] * 100))\n",
    "        # add the final b2 sequence\n",
    "    seq.append(b2.seq)  # add the last sequence\n",
    "    seqs[name] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('a2.contigs.fa', 'w') as outf:\n",
    "    for i, x in enumerate(seqs['A2']):\n",
    "        write_fasta(outf, str(i), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%mkdir -p assemblies_v2\n",
    "from tools.procOps import *\n",
    "for name, seq in seqs.iteritems():\n",
    "    with open('assemblies_v2/{}.fa'.format(name), 'w') as outf:\n",
    "        write_fasta(outf, name, ''.join(seq))\n",
    "    cmd = [['bwa', 'mem', '-t', '4', '-x', 'intractg', '/hive/groups/recon/10x_genomics/references/refdata-hsapiens-hg38/fasta/genome.fa', \n",
    "            'assemblies_v2/{}.fa'.format(name)],\n",
    "           ['samtools', 'view', '-b', '-'],\n",
    "           ['sambamba', 'sort', '-o', 'assemblies_v2/{}.hg38.bam'.format(name), '/dev/stdin']]\n",
    "    run_proc(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 contig-100_16 contig-100_5\n",
      "overlap 2387\n",
      "1 contig-100_5 contig-100_3\n",
      "gap 15207\n",
      "2 contig-100_3 contig-100_4\n",
      "overlap 24196\n",
      "3 contig-100_4 contig-100_4\n",
      "merge 6228\n",
      "5 contig-100_20 contig-100_2\n",
      "gap 2067\n",
      "6 contig-100_2 contig-100_11\n",
      "overlap 28191\n",
      "7 contig-100_11 contig-100_0\n",
      "overlap 5100\n",
      "8 contig-100_0 contig-100_6\n",
      "gap 44344\n",
      "9 contig-100_6 contig-100_1\n",
      "overlap 15128\n",
      "10 contig-100_1 contig-100_7\n",
      "overlap 32854\n"
     ]
    }
   ],
   "source": [
    "name = 'A2'\n",
    "mb = filtered_blocks[name]\n",
    "seq = []\n",
    "a, b = tee(mb)\n",
    "_ = next(b, None)\n",
    "merged = set()\n",
    "for i, (b1, b2) in enumerate(izip(a, b)):\n",
    "    if b1.qname in merged:\n",
    "        continue\n",
    "    print i, b1.qname, b2.qname\n",
    "    if b1.qname == b2.qname:\n",
    "        print 'merge', len(m)\n",
    "        m = merge_same(b1, b2)\n",
    "        if name in ['A1', 'A2', 'B1', 'B2', 'N1', 'N2']:\n",
    "            m = reverse_complement(m)\n",
    "        seq.append(m)\n",
    "        merged.add(b1.qname)\n",
    "    elif b2.msa_start < b1.msa_stop:  # we have an overlap, try to resolve via pairwise alignment\n",
    "        o = find_overlap(b1, b2)\n",
    "        print 'overlap', len(o)\n",
    "        if name in ['A1', 'A2', 'B1', 'B2', 'N1', 'N2']:\n",
    "            o = reverse_complement(o)\n",
    "        seq.append(o)\n",
    "    elif b1.msa_stop == b2.msa_start:\n",
    "        print 'same start/stop', len(b1.seq)\n",
    "        if name in ['A1', 'A2', 'B1', 'B2', 'N1', 'N2']:\n",
    "            s = reverse_complement(b1.seq)\n",
    "        else:\n",
    "            s = b1.seq\n",
    "        seq.append(s)\n",
    "    else:\n",
    "        if name in ['A1', 'A2', 'B1', 'B2', 'N1', 'N2']:\n",
    "            s = reverse_complement(b1.seq)\n",
    "        else:\n",
    "            s = b1.seq\n",
    "        seq.append(s)\n",
    "        seq.append(''.join(['N'] * 100))\n",
    "        print 'gap', len(b1.seq)\n",
    "if name in ['A1', 'A2', 'B1', 'B2', 'N1', 'N2']:\n",
    "    s = reverse_complement(b2.seq)\n",
    "else:\n",
    "    s = b2.seq\n",
    "seq.append(s)  # add the last sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = blocks['A2']\n",
    "mb = []\n",
    "for start, end, qname, seq, seq_start, seq_end in b:\n",
    "    closest_start = find_closest(sorted_positions, start)\n",
    "    closest_stop = find_closest(sorted_positions, end)\n",
    "    msa_start = final_map[closest_start]\n",
    "    msa_stop = final_map[closest_stop]\n",
    "    if msa_start > msa_stop:  # handle negative strand\n",
    "        msa_start, msa_stop = msa_stop, msa_start\n",
    "        seq = reverse_complement(seq)\n",
    "    assert len(seq) > 0\n",
    "    mb.append(Record(msa_start, msa_stop, qname, seq, seq_start, seq_end))\n",
    "# sort these to be in notch2nl order\n",
    "mb = sorted(mb, key=lambda x: x.msa_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract all alignments, discarding those not in our ROIs\n",
    "b = []\n",
    "for aln in pysam.Samfile(bam):\n",
    "    if aln.is_unmapped:\n",
    "        continue\n",
    "    start = aln.reference_start\n",
    "    end = aln.reference_end\n",
    "    c = ChromosomeInterval('chr1', start, end, '.')\n",
    "    if not interval_not_intersect_intervals(regions_of_interest, c) and len(c) > 100:\n",
    "        b.append([start, end, aln.qname, aln.seq, aln.qstart, aln.qstart + aln.alen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "11",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-600a753e6ec7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_map\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhg38_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhg38_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_pos\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpos_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0maln_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq_aln_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_pos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maln_pos\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhg38_pos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 11"
     ]
    }
   ],
   "source": [
    "aln_f = Fasta(n2nl_aln)\n",
    "seq_aln_map = defaultdict(dict)\n",
    "for name, seq in aln_f.iteritems():\n",
    "    seq_pos = 0\n",
    "    for aln_pos, x in enumerate(str(seq)):\n",
    "        seq_aln_map[name][seq_pos] = aln_pos\n",
    "        if x != '-':\n",
    "            seq_pos += 1\n",
    "\n",
    "# find maximum position for reversing negative strand\n",
    "max_pos = {x: max(y.keys()) for x, y in seq_aln_map.iteritems()}\n",
    "\n",
    "# construct a hg38 -> sequence positions using the sequences trivially mapped back to hg38\n",
    "hg38_map = {}\n",
    "for rec in pysam.Samfile(hg38_bam):\n",
    "    m = {y: x for x, y in rec.aligned_pairs}\n",
    "    # invert positions for negative strand genes\n",
    "    if rec.qname in ['NOTCH2', 'NOTCH2NL-A', 'NOTCH2NL-B']:\n",
    "        m = {x: max_pos[rec.qname] - y for x, y in m.iteritems()}\n",
    "    hg38_map[rec.qname] = m\n",
    "\n",
    "# construct a table mapping each alignment position to all hg38 positions\n",
    "r = defaultdict(dict)\n",
    "for name, pos_map in hg38_map.iteritems():\n",
    "    for hg38_pos, seq_pos in pos_map.iteritems():\n",
    "        aln_pos = seq_aln_map[name][seq_pos]\n",
    "        r[name][aln_pos] = hg38_pos\n",
    "\n",
    "# now invert this map, so that we have our hg38 -> aln map\n",
    "final_map = {}\n",
    "for name in r:\n",
    "    for aln_pos in r[name]:\n",
    "        hg38_pos = r[name][aln_pos]\n",
    "        assert hg38_pos not in final_map\n",
    "        final_map[hg38_pos] = aln_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
